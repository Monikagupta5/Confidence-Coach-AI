{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOlcpqM6JjgX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OiYgg0PJ6NHX",
        "outputId": "72ed8122-e37e-47f0-ea6b-6b9ba0dc5758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.6)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.34.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.41.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (0.0.19)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn nest-asyncio pyngrok spacy transformers\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install SpeechRecognition\n",
        "!pip install pydub\n",
        "!pip install python-dotenv\n",
        "!pip install python-multipart\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKB5gDkK8jd8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import nest_asyncio\n",
        "import random\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, UploadFile\n",
        "from pydantic import BaseModel\n",
        "import spacy\n",
        "import logging\n",
        "import speech_recognition as sr\n",
        "from typing import List\n",
        "import re\n",
        "from difflib import SequenceMatcher\n",
        "from pydub import AudioSegment\n",
        "import tempfile\n",
        "\n",
        "# Load spaCy model for NLP tasks\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define patterns for low-confidence language\n",
        "LOW_CONFIDENCE_PATTERNS = [\n",
        "    (\"I just think\", \"Consider removing 'just' to make it more assertive.\"),\n",
        "    (\"I'm sorry\", \"Avoid excessive apologizing unless necessary.\"),\n",
        "    (\"maybe\", \"Try using more definitive words.\"),\n",
        "    (\"I could be wrong, but\", \"Consider removing the disclaimer to sound more confident.\"),\n",
        "    (\"I think\", \"Consider removing 'I think' to sound more confident.\"),\n",
        "    (\"perhaps\", \"Replace 'perhaps' with a more definitive word.\"),\n",
        "    (\"I can't do it\", \"Consider using positive language.\"),\n",
        "    (\"I'm not sure\", \"Avoid showing uncertainty. Use a confident statement instead.\"),\n",
        "    (\"unsure\", \"Replace with a more assertive phrase.\"),\n",
        "    (\"totally unsure\", \"Replace with a confident alternative.\"),\n",
        "    (\"we should consider\", \"Use 'we must' or 'we will' for assertiveness.\")\n",
        "]\n",
        "\n",
        "# Enhanced passive voice detection function\n",
        "def detect_passive_voice(doc):\n",
        "    passive_suggestions = []\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"auxpass\" and token.head.pos_ == \"VERB\":\n",
        "            agent = [child for child in token.head.children if child.dep_ == \"agent\"]\n",
        "            if agent:\n",
        "                passive_suggestions.append(f\"Passive voice detected: '{token.head.text}' with agent '{agent[0].text}'\")\n",
        "            else:\n",
        "                passive_suggestions.append(f\"Passive voice detected: '{token.head.text}'\")\n",
        "    return passive_suggestions\n",
        "\n",
        "# Analyze text using spaCy and provide suggestions\n",
        "def analyze_text_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    passive_voice_suggestions = detect_passive_voice(doc)\n",
        "    section_scores = []\n",
        "    suggestions = []\n",
        "    confidence_score = 5  # Full confidence to start with\n",
        "\n",
        "    for sent in doc.sents:\n",
        "        score = 5\n",
        "        local_suggestions = []\n",
        "        for pattern, suggestion in LOW_CONFIDENCE_PATTERNS:\n",
        "            if re.search(re.escape(pattern), sent.text, re.IGNORECASE):\n",
        "                local_suggestions.append((pattern, suggestion))\n",
        "                score -= 1  # Deduct points for each pattern match\n",
        "\n",
        "        section_scores.append({\n",
        "            \"text\": sent.text,\n",
        "            \"confidence_score\": score,\n",
        "            \"suggestions\": local_suggestions\n",
        "        })\n",
        "        suggestions.extend(local_suggestions)\n",
        "\n",
        "    overall_score = max(1, confidence_score - len(suggestions))\n",
        "    return {\n",
        "        \"overall_confidence_score\": overall_score,\n",
        "        \"section_scores\": section_scores,\n",
        "        \"passive_voice_suggestions\": passive_voice_suggestions,\n",
        "        \"highlighted_text\": [str(ent) for ent in doc.ents],\n",
        "        \"suggestions\": suggestions\n",
        "    }\n",
        "\n",
        "# Generate synthetic data for ML\n",
        "def generate_synthetic_data():\n",
        "    base_phrases = [\n",
        "        (\"I just think\", \"Underconfident\"),\n",
        "        (\"I'm sorry\", \"Underconfident\"),\n",
        "        (\"maybe\", \"Underconfident\"),\n",
        "        (\"I could be wrong, but\", \"Underconfident\"),\n",
        "        (\"I think\", \"Underconfident\"),\n",
        "        (\"perhaps\", \"Underconfident\"),\n",
        "        (\"I'm not sure\", \"Underconfident\"),\n",
        "        (\"unsure\", \"Underconfident\"),\n",
        "        (\"totally unsure\", \"Underconfident\"),\n",
        "        (\"I can't do it\", \"Underconfident\"),\n",
        "        (\"This is a good idea.\", \"Neutral\"),\n",
        "        (\"I am the best\", \"Neutral\"),\n",
        "        (\"I can do it\", \"Neutral\"),\n",
        "        (\"Let's move forward with this strategy.\", \"Neutral\"),\n",
        "        (\"It is possible\", \"Neutral\"),\n",
        "        (\"Responses may delay\", \"Neutral\"),\n",
        "        (\"Data steps for ML analysis\", \"Neutral\")\n",
        "    ]\n",
        "\n",
        "    synthetic_data = []\n",
        "    for phrase, label in base_phrases:\n",
        "        for _ in range(50):\n",
        "            random_suffix = f\" {random.choice(['!', 'maybe?', 'surely.', 'variation'])}\"\n",
        "            variation = phrase + random_suffix\n",
        "            synthetic_data.append((variation, label))\n",
        "\n",
        "    return synthetic_data\n",
        "\n",
        "# Initial dataset\n",
        "data = generate_synthetic_data()\n",
        "df = pd.DataFrame(data, columns=[\"Text\", \"Label\"])\n",
        "label_map = {\"Underconfident\": 0, \"Neutral\": 1}\n",
        "df[\"Label\"] = df[\"Label\"].map(label_map)\n",
        "\n",
        "# Feature extraction and training ML model\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df[\"Text\"])\n",
        "y = df[\"Label\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Function to classify text using ML model\n",
        "def classify_text_ml(input_text):\n",
        "    input_vec = vectorizer.transform([input_text])\n",
        "    probabilities = model.predict_proba(input_vec)\n",
        "    reverse_label_map = {v: k for k, v in label_map.items()}\n",
        "    return {\n",
        "        \"label\": reverse_label_map[np.argmax(probabilities)],\n",
        "        \"confidence_scores\": {reverse_label_map[i]: prob for i, prob in enumerate(probabilities[0])}\n",
        "    }\n",
        "\n",
        "# Save user-submitted data\n",
        "def save_user_submission(text, label):\n",
        "    new_data = pd.DataFrame([[text, label]], columns=[\"Text\", \"Label\"])\n",
        "    try:\n",
        "        new_data.to_csv(\"user_submissions.csv\", mode=\"a\", header=False, index=False)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error saving user submission: {str(e)}\")\n",
        "\n",
        "# Retrain the model\n",
        "def retrain_model():\n",
        "    \"\"\"\n",
        "    Retrains the ML model using new user-submitted data stored in `user_submissions.csv`.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If there is an issue with the input data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load new user submissions\n",
        "        new_data = pd.read_csv(\"user_submissions.csv\", names=[\"Text\", \"Label\"])\n",
        "\n",
        "        # Combine the original and new data\n",
        "        updated_data = pd.concat([df, new_data], ignore_index=True)\n",
        "\n",
        "        # Ensure labels are properly mapped\n",
        "        updated_data[\"Label\"] = updated_data[\"Label\"].map(label_map)\n",
        "        if updated_data[\"Label\"].isnull().any():\n",
        "            raise ValueError(\"Invalid labels found in user submissions.\")\n",
        "\n",
        "        # Re-vectorize the combined data\n",
        "        X = vectorizer.fit_transform(updated_data[\"Text\"])\n",
        "        y = updated_data[\"Label\"]\n",
        "\n",
        "        # Retrain the global model\n",
        "        global model\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X, y)\n",
        "\n",
        "        logging.info(\"Model retrained successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        logging.error(\"User submissions file not found. Retraining skipped.\")\n",
        "        raise ValueError(\"No user submissions available for retraining.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error retraining model: {str(e)}\")\n",
        "        raise ValueError(f\"Retraining failed: {str(e)}\")\n",
        "\n",
        "\n",
        "# Transcribe audio to text\n",
        "def convert_audio_to_wav(file):\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "    temp_wav_path = f\"{temp_dir}/converted.wav\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file)\n",
        "        audio.export(temp_wav_path, format=\"wav\")\n",
        "        return temp_wav_path\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error converting audio: {str(e)}\")\n",
        "        raise ValueError(\"Error converting audio to WAV format.\")\n",
        "\n",
        "def transcribe_speech(file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    try:\n",
        "        wav_path = convert_audio_to_wav(file)\n",
        "        with sr.AudioFile(wav_path) as source:\n",
        "            audio = recognizer.record(source)\n",
        "        return recognizer.recognize_google(audio)\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Unable to recognize speech. Please try again.\"\n",
        "    except sr.RequestError as e:\n",
        "        return f\"Speech Recognition API unavailable: {e}\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error transcribing audio: {str(e)}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# FastAPI app definition\n",
        "app = FastAPI()\n",
        "user_revisions = {}\n",
        "\n",
        "class UserInput(BaseModel):\n",
        "    text: str\n",
        "\n",
        "@app.post(\"/classify/\")\n",
        "def classify_text_api(input: UserInput):\n",
        "    ml_result = classify_text_ml(input.text)\n",
        "    spacy_result = analyze_text_spacy(input.text)\n",
        "    return {\n",
        "        \"text\": input.text,\n",
        "        \"classification\": ml_result,\n",
        "        \"spacy_analysis\": spacy_result\n",
        "    }\n",
        "\n",
        "@app.post(\"/transcribe/\")\n",
        "async def transcribe_audio(file: UploadFile):\n",
        "    try:\n",
        "        text = transcribe_speech(file.file)\n",
        "        if \"Error\" in text:\n",
        "            return {\"error\": text}\n",
        "        spacy_result = analyze_text_spacy(text)\n",
        "        ml_result = classify_text_ml(text)\n",
        "        return {\n",
        "            \"text\": text,\n",
        "            \"classification\": ml_result,\n",
        "            \"spacy_analysis\": spacy_result\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in /transcribe/ endpoint: {str(e)}\")\n",
        "        return {\"error\": f\"Failed to process the audio file: {str(e)}\"}\n",
        "\n",
        "@app.post(\"/submit/\")\n",
        "def submit_text(user_id: str, text: str):\n",
        "    if user_id not in user_revisions:\n",
        "        user_revisions[user_id] = []\n",
        "    previous_text = user_revisions[user_id][-1] if user_revisions[user_id] else \"\"\n",
        "    similarity = SequenceMatcher(None, previous_text, text).ratio()\n",
        "    ml_result = classify_text_ml(text)\n",
        "    save_user_submission(text, ml_result[\"label\"])\n",
        "    user_revisions[user_id].append(text)\n",
        "    return {\n",
        "        \"message\": \"Text submitted successfully\",\n",
        "        \"history\": user_revisions[user_id],\n",
        "        \"similarity_with_previous\": f\"{similarity:.2f}\"\n",
        "    }\n",
        "\n",
        "@app.post(\"/retrain/\")\n",
        "def retrain():\n",
        "    \"\"\"\n",
        "    Endpoint to retrain the model using saved user submissions.\n",
        "\n",
        "    Returns:\n",
        "        JSON response indicating success or failure of the retraining process.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        retrain_model()\n",
        "        return {\"message\": \"Model retrained successfully with new user data.\"}\n",
        "    except ValueError as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It5xyM-n8vp9",
        "outputId": "92941ce7-dd62-4c48-93ce-36c774fcb24c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok config add-authtoken 2q58dFTb2DoAUxBGqQml8NBY3PV_7t2PVEx1y3uXGqriNDSYy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHv-KYOODcDI",
        "outputId": "9b0b1f56-9ef0-49e1-c303-a530329303b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97        95\n",
            "           1       0.99      0.93      0.96        75\n",
            "\n",
            "    accuracy                           0.96       170\n",
            "   macro avg       0.97      0.96      0.96       170\n",
            "weighted avg       0.97      0.96      0.96       170\n",
            "\n",
            "Public URL: NgrokTunnel: \"https://952e-34-48-147-134.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [16315]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     2003:fe:470b:153a:40a5:1220:45a3:200d:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2003:fe:470b:153a:40a5:1220:45a3:200d:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     2003:fe:470b:153a:40a5:1220:45a3:200d:0 - \"POST /classify/ HTTP/1.1\" 200 OK\n",
            "INFO:     2003:fe:470b:153a:da1:4c7d:19e2:979d:0 - \"POST /classify/ HTTP/1.1\" 200 OK\n",
            "INFO:     2003:fe:470b:153a:da1:4c7d:19e2:979d:0 - \"POST /transcribe/ HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model performance\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Allow nested asyncio loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Set up ngrok\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Start the server\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}